@inproceedings{10.1145/3610978.3638358,
  title = {Building Each Other up: {{Using}} Variation Theory to Build and Correct Human Mental Models of Robots},
  booktitle = {Companion of the 2024 {{ACM}}/{{IEEE}} International Conference on Human-Robot Interaction},
  author = {Horter, Tiffany},
  year = {2024},
  series = {Hri '24},
  pages = {103--105},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3610978.3638358},
  abstract = {As we begin to coexist with robots, we must be able to anticipate each other's future actions to avoid dangerous or inefficient situations. How can we build up human and robot conceptual models to predict how each other will behave? To do this, I study how to apply human concept learning theories, like variation theory, to human-robot interaction. I have found that the contrast step of variation theory (showing contrasting examples of policies when learning about robot motions) improves people's ability to predict motion in unseen settings. For my proposed PhD, I seek to connect this idea of improving a human's model of the robot with enabling the robot to correct the human's model or alter its own behavior based on its model of the shortcomings in the human's understanding.},
  isbn = {9798400703232},
  keywords = {cognitive science,mental models,robot motion,variation theory}
}

@phdthesis{Horter.2024,
  type = {Senior {{Thesis}}},
  title = {Getting {{In Your Robot}}'s {{Head}}: {{Building Mental Models}} of {{Robots Using Human-Concept Learning}}},
  author = {Horter, Tiffany},
  year = {2024},
  abstract = {To collaborate effectively and safely with machine partners, it is essential to understand and be able to predict how they will behave. This thesis explores how using variation theory [1], a human-concept learning theory from cognitive science, to select training demonstrations of agent/robot behavior impacts people's understanding of how the agent will act. By helping people improve their mental model of the artificial agents they interact with, the goal is to improve people's ability to predict their particular machine's behavior. To best teach people a concept, variation theory proposes a teaching method composed of four steps: familiarization, contrast, generalization, and fusion [1]. In prior work [2], the contrast step was compared to familiarization in the domain of a robotic arm's movement, and results suggested that contrast particularly helped people's understanding in unseen scenarios. In this study, the first three steps of variation were tested to determine which steps are most beneficial to human's learning of an agent's behavior in a self-driving domain and which, therefore, should be prioritized when training. To test differences in participants' ability to predict across these different teaching methods, a user study was run to establish the efficacy of each method by using each method to train people on various policies of a self-driving car's motion. Results suggested that being shown the combined steps of variation theory improve people's ability to predict agent behavior, especially in scenarios they were trained with. However, the step of generalization was particularly helpful for scenarios that subjects had not encountered, improving accuracy from familiarization by 9\%. Using the full steps of variation theory also increased people's trust in the agent, but results appeared to be policy-dependent. Interestingly, trust in the agent appears separate from people's true understanding of the agent's policy -- though contrast had the lowest overall correctness, people trained with that method had the highest trust in their agent at 65.9\%.},
  collaborator = {Vinitha, Gadiraju and Booth, Serena and Shah, Julie A.},
  school = {Wellesley College}
}

@inproceedings{HorterEtAl.a,
  title = {Varying {{How We Teach}}: {{Adding Contrast Helps Humans Learn}} about  {{Robot Motions}}},
  booktitle = {2023 {{HRI Workshop}} on {{Human-Interactive Robot Learning}}},
  author = {Horter, Tiffany and Glassman, Elena L. and Shah, Julie and Booth, Serena},
  abstract = {Learning how robots move is difficult, but theories of human concept learning can be applied to support humans in this task. We draw insights from the Variation Theory of Learning, a theory that has been validated in the learning sciences through decades of classroom- based studies. Variation Theory prescribes experiencing patterns of structured variation, where some aspects of concepts are held constant while other aspects vary. The result of experiencing these structured patterns is that human learners develop accurate and flexible conceptual models. Through a preliminary study, we show that using insights from Variation Theory improves humans' ability to predict robot motions: accuracy in predicting motions increases from 52.4\% using a familiarization-based strategy to 70.2\% using a Variation-based strategy. Applying Variation Theory especially increases the human's accuracy in predicting robot motions in novel settings (increasing from 50.0\% to 72.4\% accuracy).}
}
